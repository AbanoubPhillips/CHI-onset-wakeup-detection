{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d699eda",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-15T02:03:56.881504Z",
     "iopub.status.busy": "2024-08-15T02:03:56.880640Z",
     "iopub.status.idle": "2024-08-15T02:04:05.268645Z",
     "shell.execute_reply": "2024-08-15T02:04:05.267434Z"
    },
    "papermill": {
     "duration": 8.397399,
     "end_time": "2024-08-15T02:04:05.271373",
     "exception": false,
     "start_time": "2024-08-15T02:03:56.873974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from math import pi, sqrt, exp\n",
    "import sklearn,sklearn.model_selection\n",
    "import torch\n",
    "from torch import nn,Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa \n",
    "import ctypes\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b5e077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:04:05.286807Z",
     "iopub.status.busy": "2024-08-15T02:04:05.286401Z",
     "iopub.status.idle": "2024-08-15T02:04:05.313814Z",
     "shell.execute_reply": "2024-08-15T02:04:05.312682Z"
    },
    "papermill": {
     "duration": 0.036495,
     "end_time": "2024-08-15T02:04:05.316322",
     "exception": false,
     "start_time": "2024-08-15T02:04:05.279827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PATHS:\n",
    "    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n",
    "    # CSV FILES : \n",
    "    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n",
    "    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n",
    "    # PARQUET FILES:\n",
    "    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n",
    "    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"\n",
    "class CFG:\n",
    "    DEMO_MODE = True\n",
    "class data_reader:\n",
    "    def __init__(self, demo_mode):\n",
    "        super().__init__()\n",
    "        # MAPPING FOR DATA LOADING :\n",
    "        self.names_mapping = {\n",
    "            \"submission\" : {\"path\" : PATHS.SUBMISSION, \"is_parquet\" : False, \"has_timestamp\" : False}, \n",
    "            \"train_events\" : {\"path\" : PATHS.TRAIN_EVENTS, \"is_parquet\" : False, \"has_timestamp\" : True},\n",
    "            \"train_series\" : {\"path\" : PATHS.TRAIN_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True},\n",
    "            \"test_series\" : {\"path\" : PATHS.TEST_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True}\n",
    "        }\n",
    "        self.valid_names = [\"submission\", \"train_events\", \"train_series\", \"test_series\"]\n",
    "        self.demo_mode = demo_mode\n",
    "    \n",
    "    def verify(self, data_name):\n",
    "        \"function for data name verification\"\n",
    "        if data_name not in self.valid_names:\n",
    "            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE : \", valid_names)\n",
    "        return\n",
    "    \n",
    "    def cleaning(self, data):\n",
    "        \"cleaning function : drop na values\"\n",
    "        before_cleaning = len(data)\n",
    "        print(\"Number of missing timestamps : \", len(data[data[\"timestamp\"].isna()]))\n",
    "        data = data.dropna(subset=[\"timestamp\"])\n",
    "        after_cleaning = len(data)\n",
    "        print(\"Percentage of removed rows : {:.1f}%\".format(100 * (before_cleaning - after_cleaning) / before_cleaning) )\n",
    "#         print(data.isna().any())\n",
    "#         data = data.bfill()\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def reduce_memory_usage(data):\n",
    "        \"iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\n",
    "        start_mem = data.memory_usage().sum() / 1024**2\n",
    "        print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "        for col in data.columns:\n",
    "            col_type = data[col].dtype    \n",
    "            if col_type != object:\n",
    "                c_min = data[col].min()\n",
    "                c_max = data[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        data[col] = data[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        data[col] = data[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        data[col] = data[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        data[col] = data[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        data[col] = data[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        data[col] = data[col].astype(np.float32)\n",
    "                    else:\n",
    "                        data[col] = data[col].astype(np.float64)\n",
    "            else:\n",
    "                data[col] = data[col].astype('category')\n",
    "\n",
    "        end_mem = data.memory_usage().sum() / 1024**2\n",
    "        print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "        return data\n",
    "    \n",
    "    def load_data(self, data_name):\n",
    "        \"function for data loading\"\n",
    "        self.verify(data_name)\n",
    "        data_props = self.names_mapping[data_name]\n",
    "        if data_props[\"is_parquet\"]:\n",
    "            if self.demo_mode:\n",
    "                pf = ParquetFile(data_props[\"path\"]) \n",
    "                demo_rows = next(pf.iter_batches(batch_size=17280)) \n",
    "                data = pa.Table.from_batches([demo_rows]).to_pandas()\n",
    "            else:\n",
    "                data = pd.read_parquet(data_props[\"path\"])\n",
    "        else:\n",
    "            if self.demo_mode:\n",
    "                data = pd.read_csv(data_props[\"path\"], nrows=17280)\n",
    "            else:\n",
    "                data = pd.read_csv(data_props[\"path\"])\n",
    "                \n",
    "        gc.collect()\n",
    "        if data_props[\"has_timestamp\"]:\n",
    "            print('cleaning')\n",
    "            data = self.cleaning(data)\n",
    "            gc.collect()\n",
    "        data = self.reduce_memory_usage(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bcd0e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:04:05.327777Z",
     "iopub.status.busy": "2024-08-15T02:04:05.327374Z",
     "iopub.status.idle": "2024-08-15T02:04:05.976355Z",
     "shell.execute_reply": "2024-08-15T02:04:05.975206Z"
    },
    "papermill": {
     "duration": 0.657488,
     "end_time": "2024-08-15T02:04:05.978717",
     "exception": false,
     "start_time": "2024-08-15T02:04:05.321229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning\n",
      "Number of missing timestamps :  0\n",
      "Percentage of removed rows : 0.0%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by -92.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = data_reader(demo_mode=False)\n",
    "test_series = reader.load_data(data_name=\"test_series\")\n",
    "ids = test_series.series_id.unique()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c7fb47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:04:05.990865Z",
     "iopub.status.busy": "2024-08-15T02:04:05.990429Z",
     "iopub.status.idle": "2024-08-15T02:04:06.007816Z",
     "shell.execute_reply": "2024-08-15T02:04:06.006843Z"
    },
    "papermill": {
     "duration": 0.026591,
     "end_time": "2024-08-15T02:04:06.010300",
     "exception": false,
     "start_time": "2024-08-15T02:04:05.983709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBiGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers=1, bidir=True):\n",
    "        super(ResidualBiGRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidir,\n",
    "        )\n",
    "        dir_factor = 2 if bidir else 1\n",
    "        self.fc1 = nn.Linear(\n",
    "            hidden_size * dir_factor, hidden_size * dir_factor * 2\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden_size * dir_factor * 2)\n",
    "        self.fc2 = nn.Linear(hidden_size * dir_factor * 2, hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        res, new_h = self.gru(x, h)\n",
    "        # res.shape = (batch_size, sequence_size, 2*hidden_size)\n",
    "\n",
    "        res = self.fc1(res)\n",
    "        res = self.ln1(res)\n",
    "        res = nn.functional.relu(res)\n",
    "\n",
    "        res = self.fc2(res)\n",
    "        res = self.ln2(res)\n",
    "        res = nn.functional.relu(res)\n",
    "\n",
    "        # skip connection\n",
    "        res = res + x\n",
    "\n",
    "        return res, new_h\n",
    "\n",
    "class MultiResidualBiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers, bidir=True):\n",
    "        super(MultiResidualBiGRU, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.fc_in = nn.Linear(input_size, hidden_size)\n",
    "        self.ln = nn.LayerNorm(hidden_size)\n",
    "        self.res_bigrus = nn.ModuleList(\n",
    "            [\n",
    "                ResidualBiGRU(hidden_size, n_layers=1, bidir=bidir)\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        # if we are at the beginning of a sequence (no hidden state)\n",
    "        if h is None:\n",
    "            # (re)initialize the hidden state\n",
    "            h = [None for _ in range(self.n_layers)]\n",
    "\n",
    "        x = self.fc_in(x)\n",
    "        x = self.ln(x)\n",
    "        x = nn.functional.relu(x)\n",
    "\n",
    "        new_h = []\n",
    "        for i, res_bigru in enumerate(self.res_bigrus):\n",
    "            x, new_hi = res_bigru(x, h[i])\n",
    "            new_h.append(new_hi)\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "#         x = F.normalize(x,dim=0)\n",
    "        return x, new_h  # log probabilities + hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23624fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:04:06.022185Z",
     "iopub.status.busy": "2024-08-15T02:04:06.021760Z",
     "iopub.status.idle": "2024-08-15T02:04:06.026893Z",
     "shell.execute_reply": "2024-08-15T02:04:06.025789Z"
    },
    "papermill": {
     "duration": 0.013826,
     "end_time": "2024-08-15T02:04:06.029254",
     "exception": false,
     "start_time": "2024-08-15T02:04:06.015428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_FREQ = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df6e9302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:04:06.041053Z",
     "iopub.status.busy": "2024-08-15T02:04:06.040633Z",
     "iopub.status.idle": "2024-08-15T02:04:06.254407Z",
     "shell.execute_reply": "2024-08-15T02:04:06.253307Z"
    },
    "papermill": {
     "duration": 0.225358,
     "end_time": "2024-08-15T02:04:06.259693",
     "exception": false,
     "start_time": "2024-08-15T02:04:06.034335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce32b855a984c7aa1cd3828c3832167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, series_ids, series):\n",
    "        self.series_ids = series_ids\n",
    "        self.series = series.reset_index()\n",
    "        self.data = []\n",
    "\n",
    "        # Load and reset index for each series ID\n",
    "        for viz_id in tqdm(series_ids):\n",
    "            self.data.append(series.loc[(series.series_id == viz_id)].copy().reset_index())\n",
    "\n",
    "    def downsample_seq_generate_features(self, feat, window_size):\n",
    "        # Downsample data and generate features\n",
    "        if len(feat) % window_size != 0:\n",
    "            feat = np.concatenate([feat, np.zeros(window_size - (len(feat) % window_size)) + feat[-1]])\n",
    "        feat = np.reshape(feat, (-1, window_size))\n",
    "        feat_mean = np.mean(feat, axis=1)\n",
    "        feat_std = np.std(feat, axis=1)\n",
    "\n",
    "        return np.vstack([feat_mean, feat_std]).T\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Extract relevant columns and convert to numpy array\n",
    "        X = self.data[index][['anglez', 'enmo']].values.astype(np.float32)\n",
    "\n",
    "        # Apply absolute value transformation to anglez column\n",
    "        X[:, 0] = np.abs(X[:, 0])\n",
    "\n",
    "        # Downsample features with different window sizes\n",
    "        features = []\n",
    "        max_len = 0\n",
    "        for window_size in [12, 360, 720]:\n",
    "            for i in range(X.shape[1]):\n",
    "                downsampled = self.downsample_seq_generate_features(X[:, i], window_size)\n",
    "                features.append(downsampled)\n",
    "                max_len = max(max_len, downsampled.shape[0])\n",
    "\n",
    "        # Ensure all features have the same length by padding\n",
    "        for i in range(len(features)):\n",
    "            if features[i].shape[0] < max_len:\n",
    "                padding = np.zeros((max_len - features[i].shape[0], features[i].shape[1]))\n",
    "                features[i] = np.vstack((features[i], padding))\n",
    "\n",
    "        # Concatenate all features along the last axis\n",
    "        X = np.concatenate(features, axis=1)\n",
    "\n",
    "        # Convert the numpy array to a torch tensor\n",
    "        X = torch.from_numpy(X)\n",
    "        return X\n",
    "\n",
    "# Create the dataset for inference\n",
    "test_ds = SleepDataset(test_series.series_id.unique(), test_series)\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff213891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:04:06.272808Z",
     "iopub.status.busy": "2024-08-15T02:04:06.271811Z",
     "iopub.status.idle": "2024-08-15T02:04:06.277010Z",
     "shell.execute_reply": "2024-08-15T02:04:06.275888Z"
    },
    "papermill": {
     "duration": 0.014763,
     "end_time": "2024-08-15T02:04:06.279948",
     "exception": false,
     "start_time": "2024-08-15T02:04:06.265185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_chunk_size = 24*60*100\n",
    "min_interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f836fb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:04:06.293177Z",
     "iopub.status.busy": "2024-08-15T02:04:06.292759Z",
     "iopub.status.idle": "2024-08-15T02:04:08.495842Z",
     "shell.execute_reply": "2024-08-15T02:04:08.494689Z"
    },
    "papermill": {
     "duration": 2.212942,
     "end_time": "2024-08-15T02:04:08.498968",
     "exception": false,
     "start_time": "2024-08-15T02:04:06.286026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you've already defined your model and loaded test_ds, device, max_chunk_size, min_interval, etc.\n",
    "model = MultiResidualBiGRU(input_size=12, hidden_size=64, out_size=2, n_layers=5).to(device).eval()\n",
    "model.load_state_dict(torch.load(f'/kaggle/input/chi-train-small-dataset/model_best.pth', map_location=device))\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "for i in range(len(test_ds)):\n",
    "    # Ensure the input data is on the correct device\n",
    "    X = test_ds[i].half().to(device)\n",
    "    \n",
    "    seq_len = X.shape[0]\n",
    "    h = None\n",
    "    pred = torch.zeros((len(X), 2), device=device).half()  # Ensure pred is also on the correct device\n",
    "    \n",
    "    for j in range(0, seq_len, max_chunk_size):\n",
    "        y_pred, h = model(X[j: j + max_chunk_size].float(), h)\n",
    "        h = [hi.detach().to(device) for hi in h]  # Ensure hidden states are on the correct device\n",
    "        pred[j: j + max_chunk_size] = y_pred.detach()\n",
    "        del y_pred\n",
    "        gc.collect()\n",
    "    \n",
    "    del h, X\n",
    "    gc.collect()\n",
    "    \n",
    "    # Move pred back to CPU for numpy operations\n",
    "    pred = pred.cpu().numpy()\n",
    "    \n",
    "    series_id = ids[i]\n",
    "    \n",
    "    days = len(pred) / (17280 / 12)\n",
    "    scores0, scores1 = np.zeros(len(pred), dtype=np.float16), np.zeros(len(pred), dtype=np.float16)\n",
    "    \n",
    "    for index in range(len(pred)):\n",
    "        if pred[index, 0] == max(pred[max(0, index - min_interval):index + min_interval, 0]):\n",
    "            scores0[index] = max(pred[max(0, index - min_interval):index + min_interval, 0])\n",
    "        if pred[index, 1] == max(pred[max(0, index - min_interval):index + min_interval, 1]):\n",
    "            scores1[index] = max(pred[max(0, index - min_interval):index + min_interval, 1])\n",
    "    \n",
    "    candidates_onset = np.argsort(scores0)[-max(1, round(days)):]\n",
    "    candidates_wakeup = np.argsort(scores1)[-max(1, round(days)):]\n",
    "    \n",
    "    onset = test_ds.data[i][['step']].iloc[np.clip(candidates_onset * 12, 0, len(test_ds.data[i]) - 1)].astype(np.int32)\n",
    "    onset['event'] = 'onset'\n",
    "    onset['series_id'] = series_id\n",
    "    onset['score'] = scores0[candidates_onset]\n",
    "    \n",
    "    wakeup = test_ds.data[i][['step']].iloc[np.clip(candidates_wakeup * 12, 0, len(test_ds.data[i]) - 1)].astype(np.int32)\n",
    "    wakeup['event'] = 'wakeup'\n",
    "    wakeup['series_id'] = series_id\n",
    "    wakeup['score'] = scores1[candidates_wakeup]\n",
    "    \n",
    "    submission = pd.concat([submission, onset, wakeup], axis=0)\n",
    "    \n",
    "    # Clean up\n",
    "    del onset, wakeup, candidates_onset, candidates_wakeup, scores0, scores1, pred, series_id\n",
    "    gc.collect()\n",
    "\n",
    "submission = submission.sort_values(['series_id', 'step']).reset_index(drop=True)\n",
    "submission['row_id'] = submission.index.astype(int)\n",
    "submission['score'] = submission['score'].fillna(submission['score'].mean())\n",
    "submission = submission[['row_id', 'series_id', 'step', 'event', 'score']]\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe79d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:04:08.512714Z",
     "iopub.status.busy": "2024-08-15T02:04:08.511773Z",
     "iopub.status.idle": "2024-08-15T02:04:08.527996Z",
     "shell.execute_reply": "2024-08-15T02:04:08.526897Z"
    },
    "papermill": {
     "duration": 0.025379,
     "end_time": "2024-08-15T02:04:08.530375",
     "exception": false,
     "start_time": "2024-08-15T02:04:08.504996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.214111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.271973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>0</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.426758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.489990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>0</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.769043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>144</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.405762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     series_id  step   event     score\n",
       "0       0  038441c925bb     0   onset  0.214111\n",
       "1       1  038441c925bb   144  wakeup  0.271973\n",
       "2       2  03d92c9f6f8a     0   onset  0.426758\n",
       "3       3  03d92c9f6f8a   144  wakeup  0.489990\n",
       "4       4  0402a003dae9     0  wakeup  0.769043\n",
       "5       5  0402a003dae9   144   onset  0.405762"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944018d5",
   "metadata": {
    "papermill": {
     "duration": 0.005285,
     "end_time": "2024-08-15T02:04:08.541366",
     "exception": false,
     "start_time": "2024-08-15T02:04:08.536081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "sourceId": 192699709,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.550816,
   "end_time": "2024-08-15T02:04:10.472176",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-15T02:03:52.921360",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a97a2b2d257484e8b95dd95b24279f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_46ef0285d9e646839d72c4b6f2d13ee5",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2ab17eff7b09473db0874afabd779c5f",
       "value": 3.0
      }
     },
     "2ab17eff7b09473db0874afabd779c5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2d463d9d6eda46b3a9fbc733efe6ab02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46ef0285d9e646839d72c4b6f2d13ee5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ce32b855a984c7aa1cd3828c3832167": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_87ad054acc4243189c18de84e5057610",
        "IPY_MODEL_0a97a2b2d257484e8b95dd95b24279f9",
        "IPY_MODEL_c826ef2982a34136a7039ef712c40fed"
       ],
       "layout": "IPY_MODEL_2d463d9d6eda46b3a9fbc733efe6ab02"
      }
     },
     "87ad054acc4243189c18de84e5057610": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8dcb291fb45e40ddbf848854f3f6e272",
       "placeholder": "​",
       "style": "IPY_MODEL_d8e03e3207b945bdbfeb147d68461d26",
       "value": "100%"
      }
     },
     "8dcb291fb45e40ddbf848854f3f6e272": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c41872654a0446cb34355956f4f7482": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c826ef2982a34136a7039ef712c40fed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9c41872654a0446cb34355956f4f7482",
       "placeholder": "​",
       "style": "IPY_MODEL_d4f174abab8641939a74ba644f2ea404",
       "value": " 3/3 [00:00&lt;00:00, 151.52it/s]"
      }
     },
     "d4f174abab8641939a74ba644f2ea404": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d8e03e3207b945bdbfeb147d68461d26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
