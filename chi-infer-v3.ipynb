{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6e9f71",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:27.161814Z",
     "iopub.status.busy": "2024-08-17T01:45:27.161471Z",
     "iopub.status.idle": "2024-08-17T01:45:34.141731Z",
     "shell.execute_reply": "2024-08-17T01:45:34.140681Z"
    },
    "papermill": {
     "duration": 6.988555,
     "end_time": "2024-08-17T01:45:34.144082",
     "exception": false,
     "start_time": "2024-08-17T01:45:27.155527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from math import pi, sqrt, exp\n",
    "import sklearn,sklearn.model_selection\n",
    "import torch\n",
    "from torch import nn,Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa \n",
    "import ctypes\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682b6e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:34.153653Z",
     "iopub.status.busy": "2024-08-17T01:45:34.153326Z",
     "iopub.status.idle": "2024-08-17T01:45:34.174297Z",
     "shell.execute_reply": "2024-08-17T01:45:34.173392Z"
    },
    "papermill": {
     "duration": 0.027774,
     "end_time": "2024-08-17T01:45:34.176249",
     "exception": false,
     "start_time": "2024-08-17T01:45:34.148475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PATHS:\n",
    "    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n",
    "    # CSV FILES : \n",
    "    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n",
    "    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n",
    "    # PARQUET FILES:\n",
    "    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n",
    "    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"\n",
    "\n",
    "class data_reader:\n",
    "    def __init__(self, demo_mode):\n",
    "        super().__init__()\n",
    "        # MAPPING FOR DATA LOADING :\n",
    "        self.names_mapping = {\n",
    "            \"submission\" : {\"path\" : PATHS.SUBMISSION, \"is_parquet\" : False, \"has_timestamp\" : False}, \n",
    "            \"train_events\" : {\"path\" : PATHS.TRAIN_EVENTS, \"is_parquet\" : False, \"has_timestamp\" : True},\n",
    "            \"train_series\" : {\"path\" : PATHS.TRAIN_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True},\n",
    "            \"test_series\" : {\"path\" : PATHS.TEST_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True}\n",
    "        }\n",
    "        self.valid_names = [\"submission\", \"train_events\", \"train_series\", \"test_series\"]\n",
    "        self.demo_mode = demo_mode\n",
    "    \n",
    "    def verify(self, data_name):\n",
    "        \"function for data name verification\"\n",
    "        if data_name not in self.valid_names:\n",
    "            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE : \", valid_names)\n",
    "        return\n",
    "    \n",
    "    def cleaning(self, data):\n",
    "        \"cleaning function : drop na values\"\n",
    "        before_cleaning = len(data)\n",
    "        print(\"Number of missing timestamps : \", len(data[data[\"timestamp\"].isna()]))\n",
    "        data = data.dropna(subset=[\"timestamp\"])\n",
    "        after_cleaning = len(data)\n",
    "        print(\"Percentage of removed rows : {:.1f}%\".format(100 * (before_cleaning - after_cleaning) / before_cleaning) )\n",
    "#         print(data.isna().any())\n",
    "#         data = data.bfill()\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def reduce_memory_usage(data):\n",
    "        \"iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\n",
    "        start_mem = data.memory_usage().sum() / 1024**2\n",
    "        print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "        for col in data.columns:\n",
    "            col_type = data[col].dtype    \n",
    "            if col_type != object:\n",
    "                c_min = data[col].min()\n",
    "                c_max = data[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        data[col] = data[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        data[col] = data[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        data[col] = data[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        data[col] = data[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        data[col] = data[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        data[col] = data[col].astype(np.float32)\n",
    "                    else:\n",
    "                        data[col] = data[col].astype(np.float64)\n",
    "            else:\n",
    "                data[col] = data[col].astype('category')\n",
    "\n",
    "        end_mem = data.memory_usage().sum() / 1024**2\n",
    "        print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "        return data\n",
    "    \n",
    "    def load_data(self, data_name):\n",
    "        \"function for data loading\"\n",
    "        self.verify(data_name)\n",
    "        data_props = self.names_mapping[data_name]\n",
    "        if data_props[\"is_parquet\"]:\n",
    "            data = pd.read_parquet(data_props[\"path\"])\n",
    "        else:\n",
    "            data = pd.read_csv(data_props[\"path\"])\n",
    "                \n",
    "        gc.collect()\n",
    "        if data_props[\"has_timestamp\"]:\n",
    "            print('cleaning')\n",
    "            data = self.cleaning(data)\n",
    "            gc.collect()\n",
    "        data = self.reduce_memory_usage(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f85caf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:34.185316Z",
     "iopub.status.busy": "2024-08-17T01:45:34.184786Z",
     "iopub.status.idle": "2024-08-17T01:45:34.730444Z",
     "shell.execute_reply": "2024-08-17T01:45:34.729477Z"
    },
    "papermill": {
     "duration": 0.552426,
     "end_time": "2024-08-17T01:45:34.732572",
     "exception": false,
     "start_time": "2024-08-17T01:45:34.180146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning\n",
      "Number of missing timestamps :  0\n",
      "Percentage of removed rows : 0.0%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by -92.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = data_reader(demo_mode=False)\n",
    "test_series = reader.load_data(data_name=\"test_series\")\n",
    "ids = test_series.series_id.unique()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312757c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:34.742550Z",
     "iopub.status.busy": "2024-08-17T01:45:34.742221Z",
     "iopub.status.idle": "2024-08-17T01:45:34.756812Z",
     "shell.execute_reply": "2024-08-17T01:45:34.755802Z"
    },
    "papermill": {
     "duration": 0.021899,
     "end_time": "2024-08-17T01:45:34.758686",
     "exception": false,
     "start_time": "2024-08-17T01:45:34.736787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBiGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers=1, bidir=True):\n",
    "        super(ResidualBiGRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidir,\n",
    "        )\n",
    "        dir_factor = 2 if bidir else 1\n",
    "        self.fc1 = nn.Linear(\n",
    "            hidden_size * dir_factor, hidden_size * dir_factor * 2\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden_size * dir_factor * 2)\n",
    "        self.fc2 = nn.Linear(hidden_size * dir_factor * 2, hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        res, new_h = self.gru(x, h)\n",
    "        # res.shape = (batch_size, sequence_size, 2*hidden_size)\n",
    "\n",
    "        res = self.fc1(res)\n",
    "        res = self.ln1(res)\n",
    "        res = nn.functional.relu(res)\n",
    "\n",
    "        res = self.fc2(res)\n",
    "        res = self.ln2(res)\n",
    "        res = nn.functional.relu(res)\n",
    "\n",
    "        # skip connection\n",
    "        res = res + x\n",
    "\n",
    "        return res, new_h\n",
    "\n",
    "class MultiResidualBiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers, bidir=True):\n",
    "        super(MultiResidualBiGRU, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.fc_in = nn.Linear(input_size, hidden_size)\n",
    "        self.ln = nn.LayerNorm(hidden_size)\n",
    "        self.res_bigrus = nn.ModuleList(\n",
    "            [\n",
    "                ResidualBiGRU(hidden_size, n_layers=1, bidir=bidir)\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        # if we are at the beginning of a sequence (no hidden state)\n",
    "        if h is None:\n",
    "            # (re)initialize the hidden state\n",
    "            h = [None for _ in range(self.n_layers)]\n",
    "\n",
    "        x = self.fc_in(x)\n",
    "        x = self.ln(x)\n",
    "        x = nn.functional.relu(x)\n",
    "\n",
    "        new_h = []\n",
    "        for i, res_bigru in enumerate(self.res_bigrus):\n",
    "            x, new_hi = res_bigru(x, h[i])\n",
    "            new_h.append(new_hi)\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "#         x = F.normalize(x,dim=0)\n",
    "        return x, new_h  # log probabilities + hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9475e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:34.768392Z",
     "iopub.status.busy": "2024-08-17T01:45:34.767860Z",
     "iopub.status.idle": "2024-08-17T01:45:34.772230Z",
     "shell.execute_reply": "2024-08-17T01:45:34.771100Z"
    },
    "papermill": {
     "duration": 0.011243,
     "end_time": "2024-08-17T01:45:34.774115",
     "exception": false,
     "start_time": "2024-08-17T01:45:34.762872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_FREQ = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143b9df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:34.783569Z",
     "iopub.status.busy": "2024-08-17T01:45:34.783247Z",
     "iopub.status.idle": "2024-08-17T01:45:34.960873Z",
     "shell.execute_reply": "2024-08-17T01:45:34.959909Z"
    },
    "papermill": {
     "duration": 0.184717,
     "end_time": "2024-08-17T01:45:34.963018",
     "exception": false,
     "start_time": "2024-08-17T01:45:34.778301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db451ac6fb4e48638d01a7bbece1a427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, series_ids, series):\n",
    "        self.series_ids = series_ids\n",
    "        self.series = series.reset_index()\n",
    "        self.data = []\n",
    "\n",
    "        # Load and reset index for each series ID\n",
    "        for viz_id in tqdm(series_ids):\n",
    "            self.data.append(series.loc[(series.series_id == viz_id)].copy().reset_index())\n",
    "\n",
    "    def downsample_seq_generate_features(self, feat, window_size):\n",
    "        # Downsample data and generate features\n",
    "        if len(feat) % window_size != 0:\n",
    "            feat = np.concatenate([feat, np.zeros(window_size - (len(feat) % window_size)) + feat[-1]])\n",
    "        feat = np.reshape(feat, (-1, window_size))\n",
    "        feat_mean = np.mean(feat, axis=1)\n",
    "        feat_std = np.std(feat, axis=1)\n",
    "\n",
    "        return np.vstack([feat_mean, feat_std]).T\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Extract relevant columns and convert to numpy array\n",
    "        X = self.data[index][['anglez', 'enmo']].values.astype(np.float32)\n",
    "\n",
    "        # Apply absolute value transformation to anglez column\n",
    "        X[:, 0] = np.abs(X[:, 0])\n",
    "\n",
    "        # Downsample features with different window sizes\n",
    "        features = []\n",
    "        max_len = 0\n",
    "        for window_size in [12, 360, 720]:\n",
    "            for i in range(X.shape[1]):\n",
    "                downsampled = self.downsample_seq_generate_features(X[:, i], window_size)\n",
    "                features.append(downsampled)\n",
    "                max_len = max(max_len, downsampled.shape[0])\n",
    "\n",
    "        # Ensure all features have the same length by padding\n",
    "        for i in range(len(features)):\n",
    "            if features[i].shape[0] < max_len:\n",
    "                padding = np.zeros((max_len - features[i].shape[0], features[i].shape[1]))\n",
    "                features[i] = np.vstack((features[i], padding))\n",
    "\n",
    "        # Concatenate all features along the last axis\n",
    "        X = np.concatenate(features, axis=1)\n",
    "\n",
    "        # Convert the numpy array to a torch tensor\n",
    "        X = torch.from_numpy(X)\n",
    "        return X\n",
    "\n",
    "# Create the dataset for inference\n",
    "test_ds = SleepDataset(test_series.series_id.unique(), test_series)\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf717d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:34.973059Z",
     "iopub.status.busy": "2024-08-17T01:45:34.972772Z",
     "iopub.status.idle": "2024-08-17T01:45:34.976588Z",
     "shell.execute_reply": "2024-08-17T01:45:34.975885Z"
    },
    "papermill": {
     "duration": 0.010954,
     "end_time": "2024-08-17T01:45:34.978506",
     "exception": false,
     "start_time": "2024-08-17T01:45:34.967552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_chunk_size = 24*60*12\n",
    "min_interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8acac09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:34.988149Z",
     "iopub.status.busy": "2024-08-17T01:45:34.987884Z",
     "iopub.status.idle": "2024-08-17T01:45:36.872971Z",
     "shell.execute_reply": "2024-08-17T01:45:36.871979Z"
    },
    "papermill": {
     "duration": 1.892609,
     "end_time": "2024-08-17T01:45:36.875344",
     "exception": false,
     "start_time": "2024-08-17T01:45:34.982735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you've already defined your model and loaded test_ds, device, max_chunk_size, min_interval, etc.\n",
    "model = MultiResidualBiGRU(input_size=12, hidden_size=64, out_size=2, n_layers=5).to(device).eval()\n",
    "model.load_state_dict(torch.load(f'/kaggle/input/chi-train-v3/model_best.pth', map_location=device))\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "for i in range(len(test_ds)):\n",
    "    # Ensure the input data is on the correct device\n",
    "    X = test_ds[i].half().to(device)\n",
    "    \n",
    "    seq_len = X.shape[0]\n",
    "    h = None\n",
    "    pred = torch.zeros((len(X), 2), device=device).half()  # Ensure pred is also on the correct device\n",
    "    \n",
    "    for j in range(0, seq_len, max_chunk_size):\n",
    "        y_pred, h = model(X[j: j + max_chunk_size].float(), h)\n",
    "        h = [hi.detach().to(device) for hi in h]  # Ensure hidden states are on the correct device\n",
    "        pred[j: j + max_chunk_size] = y_pred.detach()\n",
    "        del y_pred\n",
    "        gc.collect()\n",
    "    \n",
    "    del h, X\n",
    "    gc.collect()\n",
    "    \n",
    "    # Move pred back to CPU for numpy operations\n",
    "    pred = pred.cpu().numpy()\n",
    "    \n",
    "    series_id = ids[i]\n",
    "    \n",
    "    days = len(pred) / (17280 / 12)\n",
    "    scores0, scores1 = np.zeros(len(pred), dtype=np.float16), np.zeros(len(pred), dtype=np.float16)\n",
    "    \n",
    "    for index in range(len(pred)):\n",
    "        if pred[index, 0] == max(pred[max(0, index - min_interval):index + min_interval, 0]):\n",
    "            scores0[index] = max(pred[max(0, index - min_interval):index + min_interval, 0])\n",
    "        if pred[index, 1] == max(pred[max(0, index - min_interval):index + min_interval, 1]):\n",
    "            scores1[index] = max(pred[max(0, index - min_interval):index + min_interval, 1])\n",
    "    \n",
    "    candidates_onset = np.argsort(scores0)[-max(1, round(days)):]\n",
    "    candidates_wakeup = np.argsort(scores1)[-max(1, round(days)):]\n",
    "    \n",
    "    onset = test_ds.data[i][['step']].iloc[np.clip(candidates_onset * 12, 0, len(test_ds.data[i]) - 1)].astype(np.int32)\n",
    "    onset['event'] = 'onset'\n",
    "    onset['series_id'] = series_id\n",
    "    onset['score'] = scores0[candidates_onset]\n",
    "    \n",
    "    wakeup = test_ds.data[i][['step']].iloc[np.clip(candidates_wakeup * 12, 0, len(test_ds.data[i]) - 1)].astype(np.int32)\n",
    "    wakeup['event'] = 'wakeup'\n",
    "    wakeup['series_id'] = series_id\n",
    "    wakeup['score'] = scores1[candidates_wakeup]\n",
    "    \n",
    "    submission = pd.concat([submission, onset, wakeup], axis=0)\n",
    "    \n",
    "    # Clean up\n",
    "    del onset, wakeup, candidates_onset, candidates_wakeup, scores0, scores1, pred, series_id\n",
    "    gc.collect()\n",
    "\n",
    "submission = submission.sort_values(['series_id', 'step']).reset_index(drop=True)\n",
    "submission['row_id'] = submission.index.astype(int)\n",
    "submission['score'] = submission['score'].fillna(submission['score'].mean())\n",
    "submission = submission[['row_id', 'series_id', 'step', 'event', 'score']]\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f46a46d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T01:45:36.886972Z",
     "iopub.status.busy": "2024-08-17T01:45:36.886052Z",
     "iopub.status.idle": "2024-08-17T01:45:36.900848Z",
     "shell.execute_reply": "2024-08-17T01:45:36.899896Z"
    },
    "papermill": {
     "duration": 0.022627,
     "end_time": "2024-08-17T01:45:36.902867",
     "exception": false,
     "start_time": "2024-08-17T01:45:36.880240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>24</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.528809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>132</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.109192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>12</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.544434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.131470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>0</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.693359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>144</td>\n",
       "      <td>onset</td>\n",
       "      <td>1.395508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     series_id  step   event     score\n",
       "0       0  038441c925bb    24   onset  0.528809\n",
       "1       1  038441c925bb   132  wakeup  0.109192\n",
       "2       2  03d92c9f6f8a    12   onset  0.544434\n",
       "3       3  03d92c9f6f8a   144  wakeup  0.131470\n",
       "4       4  0402a003dae9     0  wakeup  0.693359\n",
       "5       5  0402a003dae9   144   onset  1.395508"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf88d2",
   "metadata": {
    "papermill": {
     "duration": 0.004267,
     "end_time": "2024-08-17T01:45:36.911765",
     "exception": false,
     "start_time": "2024-08-17T01:45:36.907498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "sourceId": 192921604,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.56922,
   "end_time": "2024-08-17T01:45:39.279930",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-17T01:45:23.710710",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c99bbc19ffd408eb914243e5318959c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9ff808a6a3c147968c5b6b093ab13282",
       "placeholder": "​",
       "style": "IPY_MODEL_3c757ee7dc374b3d81abf16b6a422373",
       "value": "100%"
      }
     },
     "1eab8f3958d14e33a6de30b9826082c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3c757ee7dc374b3d81abf16b6a422373": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4e166f45f8414b6aa8230b61c9e7869e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5f18ea1a030b4903aa099b63b7177242": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "625d0bf11d4949e1b7ce79c24621242f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ff808a6a3c147968c5b6b093ab13282": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbec87bdd3dc40d8a64484df7863d691": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_df6a6e93858e4bd4b36de498477948a9",
       "placeholder": "​",
       "style": "IPY_MODEL_4e166f45f8414b6aa8230b61c9e7869e",
       "value": " 3/3 [00:00&lt;00:00, 160.60it/s]"
      }
     },
     "db451ac6fb4e48638d01a7bbece1a427": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0c99bbc19ffd408eb914243e5318959c",
        "IPY_MODEL_fd55aa5a122d4870964b35f576e19f73",
        "IPY_MODEL_bbec87bdd3dc40d8a64484df7863d691"
       ],
       "layout": "IPY_MODEL_5f18ea1a030b4903aa099b63b7177242"
      }
     },
     "df6a6e93858e4bd4b36de498477948a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd55aa5a122d4870964b35f576e19f73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_625d0bf11d4949e1b7ce79c24621242f",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1eab8f3958d14e33a6de30b9826082c2",
       "value": 3.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
